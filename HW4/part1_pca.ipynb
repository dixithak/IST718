{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a78d93effa85ac1fca2a197555f87eec",
     "grade": false,
     "grade_id": "cell-7070b477be2632ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ee1f9f3c5ad1d3dbc2fd8190dd3682f",
     "grade": false,
     "grade_id": "cell-2552baebbd857fc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature, regression, Pipeline, pipeline\n",
    "from pyspark.sql import types, Row, functions as fn\n",
    "from pyspark import sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0d47acdb217726c9109224b420b5be3",
     "grade": false,
     "grade_id": "cell-c841435f1983f29f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: PCA and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a6b009df652914ac287acb6a4826fa0",
     "grade": false,
     "grade_id": "cell-426b42289f2cf1e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The government of Syracuse is trying to understand how to better keep its streets in good condition. Luckily, they have a datset obtained from patching said streets. Using this dataset, they want to easily visualize the characteristics of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cafa700d8c53c5dcdcd80dce8a4bf916",
     "grade": false,
     "grade_id": "cell-baa72903454c0f25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "syracuse_streets = spark.read.json(\"syracuse.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "349dc0a5bac30a0afbb378180177b7ad",
     "grade": false,
     "grade_id": "cell-f77095514add2e50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In particular, the city is interested in understanding the following features:\n",
    "\n",
    "- `Latitude` \n",
    "- `Longitude`\n",
    "- `crack`: number of cracks on the street (visually inspected)\n",
    "- `patch`: number of patches on the street (visually inspected)\n",
    "- `pavement`: quality of the pavement\n",
    "- `length`: street length\n",
    "- `width`: street width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the numerical features\n",
    "syracuse_streets.select(['Latitude', \n",
    "               'Longitude', \n",
    "               'crack', \n",
    "               'patch',  \n",
    "               'pavement',\n",
    "               'length', \n",
    "               'width']).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1bade042908c79a82d3958f09fdf69a",
     "grade": false,
     "grade_id": "cell-a646caf3d703079a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For some of the questions, you will use the following user-defined function that transforms a vector into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "885e77419b21d23a5c5ecc4f667a6354",
     "grade": false,
     "grade_id": "cell-42ff62379ad35f85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@fn.udf(returnType=types.ArrayType(types.FloatType()))\n",
    "def to_array(col):\n",
    "    return col.toArray().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17f5149f854ec27e67d4475921cc7091",
     "grade": false,
     "grade_id": "cell-210b6772647bea10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For example, suppose you have latitude and longitude as a column of type vector. The way Spark encodes vectors is different from arrays and therefore they are not easy to manipulable. The above function allows you to transform a vector into an array for easy manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aaa624720eb9eebd7a98c89bf63dce2",
     "grade": false,
     "grade_id": "cell-3c85bc18be3f6748",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(feature\n",
    " .VectorAssembler(inputCols=['Latitude', 'Longitude'], outputCol='feature_vector')\n",
    " .transform(syracuse_streets)\n",
    " .select('feature_vector')\n",
    " .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3e48d48397e8dcaf72bd1a3275ee2f2",
     "grade": false,
     "grade_id": "cell-09159311689eebdd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For example, we can take apart pieces of the array using `fn.expr('feature_array[i]')` notation to extract the ith element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45dd1e0f76554236a827f76ee4db76ae",
     "grade": false,
     "grade_id": "cell-6fdd5f7e34a74953",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(feature\n",
    " .VectorAssembler(inputCols=['Latitude', 'Longitude'], outputCol='feature_vector')\n",
    " .transform(syracuse_streets)\n",
    " .select(to_array('feature_vector').alias('feature_array'))\n",
    " .select(fn.expr('feature_array[0]').alias('latitude'), \n",
    "         fn.expr('feature_array[1]').alias('longitude'))\n",
    " .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7cf80debd0a57fa4f835e7dc75555cb",
     "grade": false,
     "grade_id": "cell-e9debbdcfaac4bdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can do a lot more things with arrays. Take a look at https://sparkbyexamples.com/spark/spark-sql-array-functions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7e06288508d4f11d74c1ac2570b2b66",
     "grade": false,
     "grade_id": "cell-702b9a759ce6ef99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1: (30 pts) Simple PCA\n",
    "\n",
    "In this question, you will perform PCA to understand and visualize the data. You will analyze the features `Latitude`, `Longitude`, `crack`, `patch`,  `pavement`, `length`, and `width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84266b81ec07c7d38d18fd6481a224ad",
     "grade": false,
     "grade_id": "cell-fa4a9594a71d6b27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "feature_list = ['Latitude', \n",
    "               'Longitude', \n",
    "               'crack', \n",
    "               'patch',  \n",
    "               'pavement',\n",
    "               'length', \n",
    "               'width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5eab0ff03c57e880f6e5a3b0fee6eb44",
     "grade": false,
     "grade_id": "cell-1e5eb1ce37c852a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the cell below, create a pipeline model (i.e., fitted pipeline) called `pca_2d` that takes the features above and projects them into **two** principal components. Before fitting the PCA model, make sure to **standardized** your data (i.e., center **and** divide by standard deviation) using `feature.StandardScaler`. Make sure the PCA part of the model generates an output column called `pc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcd8d01982304261ca8e89f7fb071fff",
     "grade": false,
     "grade_id": "cell-42f23e41b0dd075a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline to produce principal components of data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29eba9e5d515d192d8ff16be92f1235e",
     "grade": false,
     "grade_id": "cell-4e38faac0adbdea4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check that the fitted pipeline works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e4ff917037d02bf269b5468fe864dce",
     "grade": false,
     "grade_id": "cell-36eae5f7715b6863",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pca_2d.transform(syracuse_streets).select(feature_list + ['pc']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58ef87971670b2eedb35e184956e8b91",
     "grade": true,
     "grade_id": "cell-2ad4d5e0c8ba310f",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 15 pts\n",
    "assert type(pca_2d) == pipeline.PipelineModel\n",
    "assert type(pca_2d.stages[-1]) == feature.PCAModel\n",
    "assert set(pca_2d.stages[0].extractParamMap()[(pca_2d.stages[0].inputCols)]) == \\\n",
    " {'Longitude', 'Latitude', 'crack', 'patch', 'pavement', 'length', 'width'}\n",
    "assert feature.StandardScalerModel in list(map(type, pca_2d.stages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a39a0633ec9570dbda237243692aa8e7",
     "grade": false,
     "grade_id": "cell-af4cd18c5dc28143",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's visualize the principal components. Create a Pandas dataframe that contains the `Longitude`, PC 1 (name it `pc1`), and PC 2 (name it `pc2`). You should use the udf `to_array` defined above to pluck the first and second component of the principal component into their own columns. Call this pandas dataframe `syracuse_2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9009dc4d2d825b88ae7d45c330478929",
     "grade": false,
     "grade_id": "cell-22e538c551ea8478",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# put your code here to produce a pandas dataframe with columns Longitude, pc1, and pc2\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0719e02c92f1036f5f0635d38464c31",
     "grade": true,
     "grade_id": "cell-a05eaed0a167f628",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert set(syracuse_2d.columns) == {'Longitude', 'pc1', 'pc2'}\n",
    "assert syracuse_2d.shape[0] == syracuse_streets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8410c19ca85b234132c18e172ca4a5d",
     "grade": false,
     "grade_id": "cell-842879feaf88eadb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The code below will plot the dataframe and color points by Longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7227e5f1d982c443324d08118e2a9bc7",
     "grade": false,
     "grade_id": "cell-58b14861b3f560df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.scatterplot(data=syracuse_2d, x='pc1', y='pc2', hue=syracuse_2d.Longitude.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "489381ec4becb2a50e1d295fd288916e",
     "grade": false,
     "grade_id": "cell-bbb8807c30e3ac48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(10 pts)**: Given the plot above, do you think the *loading* on Longitude is bigger in principal component 1 or principal component 2? Elaborate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f9483f0264dead205f79a1759b95013",
     "grade": true,
     "grade_id": "cell-8213b57422a803bb",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "371c3a7e74c4811a84b16f8bae671091",
     "grade": false,
     "grade_id": "cell-7e0826cd125a9da4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2: (10 pts) More PCA\n",
    "\n",
    "In the previous section, we only limited our analysis to two principal components. However, it is unclear whether two dimensions capture enough of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10b2b2675b591a5b6fa5d6c648df81e4",
     "grade": false,
     "grade_id": "cell-77765afe51829c08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following question, fit a new PCA analysis model, similar to that of Question 1, where you include all principal components (seven principal components because length of `feature_list` is 7). Call this PCA pipeline `pca_all`. You can reuse some of the components of the pipeline above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7804cda5e96f62404a25c6afdbe52195",
     "grade": false,
     "grade_id": "cell-a5ef2ce780808a58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline to produce principal components of data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43b3feb923a1825c9ecf3aafb150e4d9",
     "grade": false,
     "grade_id": "cell-44d20d0742c32df3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your pipeline below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_all.transform(syracuse_streets).select(to_array('pc')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2d6ab3c8ec614dcb72ec189559c06ad",
     "grade": true,
     "grade_id": "cell-e016aa9ad4e060c1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert type(pca_all) == pipeline.PipelineModel\n",
    "assert type(pca_all.stages[-1]) == feature.PCAModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
