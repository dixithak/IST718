{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e32afc3220521fd5a9bbff4cec73b63",
     "grade": false,
     "grade_id": "cell-ade2cf06b0fbd2b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b22b37e081fca4745ce97cf6952e9dc",
     "grade": false,
     "grade_id": "cell-08055393264a3d49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "687516ecd6d856d5a93742443ec210b6",
     "grade": false,
     "grade_id": "cell-923bede0f3e1d4cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9a9a67555ab717c03ff4f70a31b8445",
     "grade": false,
     "grade_id": "cell-4a3c1e56d6d249d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31da6ddec218fff221f2d8257f2b31a5",
     "grade": false,
     "grade_id": "cell-957fbfa010a6000e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile(\"host_server_requests.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72fac1ed218f635c993838bd5b195d12",
     "grade": false,
     "grade_id": "cell-839c115f722f63c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "679006b9ba5e584a9549de3d5a0908e8",
     "grade": false,
     "grade_id": "cell-acec0ed673c71bec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def process_line(line):    \n",
    "    # YOUR CODE HERE\n",
    "    # METHOD 1:\n",
    "    values = []\n",
    "    values = line.split(\"|\") #splitting pipe separated values\n",
    "    a = values[7].split(\"=>\") # further splitting the last list element with '=> symbol'\n",
    "    values[7] = a[0] # assigning first value from the above split list\n",
    "    values.append(a[1].strip()) # appending second value from above split list\n",
    "    # replacing host and server values\n",
    "    if values[0] == 'HOST':\n",
    "        values[0] ='1'\n",
    "    else:\n",
    "        values[0] ='0'\n",
    "    values = [float(x) for x in values] #converting all values to float\n",
    "    return Row(f1 = values[0],f2=values[1],f3=values[2],f4=values[3],f5=values[4],f6=values[5],f7=values[6],f8=values[7],label=values[8])\n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n # METHOD 2 to generate elements:\\n        line= line.replace('=>','|')\\n    values = line.split('|')\\n    if values[0] == 'HOST':\\n        values[0] ='1'\\n    else:\\n        values[0] ='0'\\n    values = [float(x) for x in values]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " # METHOD 2 to generate elements:\n",
    "        line= line.replace('=>','|')\n",
    "    values = line.split('|')\n",
    "    if values[0] == 'HOST':\n",
    "        values[0] ='1'\n",
    "    else:\n",
    "        values[0] ='0'\n",
    "    values = [float(x) for x in values]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
       " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
       " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
       " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
       " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
       " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
       " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
       " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
       " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
       " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276f108d65eeaa2c1e3b8c811ac3cfcb",
     "grade": true,
     "grade_id": "cell-89d70831d5dc6e1c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1b0054c79694af274ba1579f3826f42",
     "grade": false,
     "grade_id": "cell-d3e65de380d61134",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create requests_df variable here\n",
    "# YOUR CODE HERE\n",
    "requests_df = spark.createDataFrame(requests_rdd.map(process_line).collect())\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1290dcae61e376310c8da70f2bcc4c16",
     "grade": true,
     "grade_id": "cell-362523b107452045",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "| f1|     f2|      f3|      f4|      f5|      f6|      f7|      f8|         label|\n",
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "|1.0| 2.0E-5| 0.80279|-0.09174| 0.04041|-0.22504| -0.0504| 0.58149| 163.877101489|\n",
      "|1.0| 5.0E-5|-0.00454| -0.0211| 0.00174|-0.11684| 0.19182|-0.23745|-105.023368852|\n",
      "|1.0| 1.5E-4|-0.10437| 0.04869| 0.18333|-0.21864| 0.27638|-0.13441|-115.011801582|\n",
      "|1.0|-1.5E-4| 0.27118| 0.14526| 0.06101| 0.13401| 0.06237|-0.74065|-122.623452696|\n",
      "|1.0|-6.0E-5|  0.1413| 0.12084| 0.05452| 0.09272|  0.2534|-0.65331|-117.130523174|\n",
      "|1.0|-8.0E-5|-0.41534|-0.04205|-0.00724|-0.07463| 0.13273| 0.19112|-73.5775668047|\n",
      "|1.0|-8.0E-5|-0.45937|-0.23509|-0.05679| 0.06077|-0.49597|-0.30668| -137.37933148|\n",
      "|0.0| 2.0E-5|-0.23465| 0.07345|-0.07217|-0.19256|-0.14377|-0.15183|-162.804738349|\n",
      "|0.0|-7.0E-5|-0.10321| 0.27467| 0.04058|-0.24541| 0.08631| -0.2979|-212.111291232|\n",
      "|1.0|-7.0E-5|-0.01039|-0.00453|-0.01352|-0.05199| -0.3772|-0.19641|-91.5022329392|\n",
      "|0.0| 6.0E-5| 0.47246| 0.17037| 0.02759| 0.05768| 0.61162| 0.42008| 161.034690581|\n",
      "|0.0| 3.0E-5|-0.04454| 0.00113| 0.05071|-0.31363|  0.1343|-0.48055|-260.368197268|\n",
      "|1.0| 7.0E-5| 0.19256| -0.2173|-0.21053| -0.1432| 0.09896| -0.0332|-39.1189294239|\n",
      "|0.0|    0.0|-0.06748|-0.20317|-0.08298| -0.0435|-0.64183|-0.04638|-73.7072587358|\n",
      "|1.0| 1.1E-4|-0.19994|  -0.103|-0.09868| 0.07626| 0.10319| 0.20899|  51.541716065|\n",
      "|0.0|-2.3E-4|-0.43976| 0.13039|-0.03269|-0.18748|  0.1892| 0.09995| -186.39307418|\n",
      "|0.0| 7.0E-5| 0.02707|-0.23733| 0.01848| 0.07501|-0.05031|-0.40946|-86.0842367649|\n",
      "|0.0| 1.1E-4|-0.01234|-0.05741|-0.05995|-0.12866| 0.05322|-0.00326|-59.6670604735|\n",
      "|0.0|-9.0E-5|-0.14319|-0.27307|-0.01018|-0.20139| 0.51239| 0.13495|-115.805881143|\n",
      "|1.0| 3.0E-5| 0.04087|-0.16027|-0.00261|   0.038|-0.17789| 0.10325|  23.358169855|\n",
      "+---+-------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "requests_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome, the count of each group and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel`, the count `label`as a column `clabel`, and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f51f62572111fb7416abe94da8b6e335",
     "grade": false,
     "grade_id": "cell-3d19258199b8a93d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the dataframe `summary_df` below\n",
    "# using aggregate functions and aliasing for renaming\n",
    "summary_df = requests_df.groupBy('f1').\\\n",
    "agg(fn.avg('label').alias('mlabel'),\n",
    "    fn.count('f1').alias('clabel'),\n",
    "    (fn.stddev_samp('label')/fn.sqrt(fn.count('f1'))).alias('semlabel')\n",
    "   )\n",
    "#summary_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- clabel: long(nullable = false)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "661768df6156209e1cc184b1db6f6a22",
     "grade": true,
     "grade_id": "cell-62d3e583f4017e21",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'clabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919212,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `var` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0c4919fa8e008bde1fde280e99e5521",
     "grade": false,
     "grade_id": "cell-b1f11325408fb1ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "var = VectorAssembler(inputCols =['f1','f2','f3','f4','f5','f6','f7','f8'],outputCol = 'features') #creating a vector assembler\n",
    "features_df = var.transform(requests_df) #transforming the data set using the vector assembler\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "| f1|    f2|      f3|      f4|     f5|      f6|     f7|      f8|         label|            features|\n",
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "|1.0|2.0E-5| 0.80279|-0.09174|0.04041|-0.22504|-0.0504| 0.58149| 163.877101489|[1.0,2.0E-5,0.802...|\n",
      "|1.0|5.0E-5|-0.00454| -0.0211|0.00174|-0.11684|0.19182|-0.23745|-105.023368852|[1.0,5.0E-5,-0.00...|\n",
      "|1.0|1.5E-4|-0.10437| 0.04869|0.18333|-0.21864|0.27638|-0.13441|-115.011801582|[1.0,1.5E-4,-0.10...|\n",
      "+---+------+--------+--------+-------+--------+-------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18db619b447231f272243029a4a63479",
     "grade": true,
     "grade_id": "cell-50ebf2b6919fad92",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "633222c8b745fdd2228639f36a150730",
     "grade": false,
     "grade_id": "cell-3054385622721159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7304999d1a342f5627b41dbfa1c4da",
     "grade": false,
     "grade_id": "cell-fa0a9a7a314d8b51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the linear regression estimator below and name it lr_model.\n",
    "# use the model to create the dataframe predictions_df with two columns label and prediction\n",
    "# by transforming the dataframe `features_df` \n",
    "# YOUR CODE HERE\n",
    "from pyspark.ml import regression\n",
    "lr_estimator = regression.LinearRegression(featuresCol=\"features\",labelCol=\"label\") #creating a linear regression estimator model\n",
    "lr_model = lr_estimator.fit(features_df) # fitting the model with the considered features\n",
    "predictions_df = lr_model.transform(features_df).select('label','prediction')# generating predictions for the selected features and labels\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f383c20b03ef892c4f8c91d912c1da88",
     "grade": true,
     "grade_id": "cell-117a01b0fbecc285",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(var), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22cc68225580587db33a2f5a6ca24ce6",
     "grade": false,
     "grade_id": "cell-b3cddc65c26cd3c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6:\n",
    "\n",
    "Try to get the R squared and adjusted R squared of the linear model by `model.summary` and assign in variable `r2` and `adj_r2`. Also, based on the `predictions_df` dataframe, count how many rows which the difference between prediction and label are greater than 5. Assign the count into `diff_5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "513a8a9be982130b83133e8e15945c14",
     "grade": false,
     "grade_id": "cell-ee9ac076ea123c1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+\n",
      "|         label|         prediction|                 abs|\n",
      "+--------------+-------------------+--------------------+\n",
      "| 163.877101489|  159.0699470833753|   4.807154405624715|\n",
      "|-105.023368852| -99.52598722329135|   5.497381628708652|\n",
      "|-115.011801582|-109.91382979074436|   5.097971791255645|\n",
      "|-122.623452696|-118.62864861627769|  3.9948040797223143|\n",
      "|-117.130523174|-116.89245751669513|  0.2380656573048725|\n",
      "|-73.5775668047| -66.83424942677468|   6.743317377925322|\n",
      "| -137.37933148|-138.26026259837553|  0.8809311183755426|\n",
      "|-162.804738349|-163.26081447999744| 0.45607613099744526|\n",
      "|-212.111291232| -212.0633066467847|0.047984585215317566|\n",
      "|-91.5022329392| -87.84291716953952|  3.6593157696604806|\n",
      "| 161.034690581| 165.41717556677597|    4.38248498577596|\n",
      "|-260.368197268|-253.18668927126717|   7.181507996732847|\n",
      "|-39.1189294239|-30.896469691695604|   8.222459732204396|\n",
      "|-73.7072587358|  -64.9648426981969|   8.742416037603093|\n",
      "|  51.541716065|  54.32244313398158|  2.7807270689815766|\n",
      "| -186.39307418| -175.2351633632155|  11.157910816784522|\n",
      "|-86.0842367649| -80.01284096829595|   6.071395796604051|\n",
      "|-59.6670604735| -59.35359940731333|  0.3134610661866688|\n",
      "|-115.805881143|-106.30556793936245|   9.500313203637546|\n",
      "|  23.358169855|  37.29467902684328|  13.936509171843284|\n",
      "+--------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "summary = lr_model.summary\n",
    "r2 = summary.r2 #getting R-Squared value\n",
    "adj_r2 = summary.r2adj #getting adjsuted R-Squared\n",
    "c = fn.col('prediction') - fn.col('label') # getting the difference between predictiona and labeled data\n",
    "predictions_df = predictions_df.withColumn('abs',abs(c)) #creating a new column with absolute value of the difference\n",
    "diff_5 = predictions_df.where(fn.col('abs') > 5).count()#counting the number of rows which satisfy tge \">5\" condition\n",
    "\n",
    "predictions_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57c93d6ae45cba264daf340ed90d3d15",
     "grade": true,
     "grade_id": "cell-c8d5da8c2f729244",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_approx_equal(r2, 0.9952916629913636, significant=3)\n",
    "np.testing.assert_approx_equal(adj_r2, 0.9952878929287003, significant=3)\n",
    "assert diff_5 == 5617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:\n",
    "\n",
    "Root Mean Square Error(RMSE) and Mean Absolute Error(MAE) are common metrics to evaluate regression model. \\\n",
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "and the mean absolute error is defined as\n",
    "\n",
    "$$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n \\left\\lvert \\hat{y}_i - y_i \\right\\rvert$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `lr_metrics_df` that contains the root mean squared error in column `rmse` and the mean absolute error in column `mae` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "878beeafe97112f69bcb9801a2f5592e",
     "grade": false,
     "grade_id": "cell-324e29f1a0af77af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# define the `lr_metrics_df` dataframe here\n",
    "# using aggregate function and aliasing to calculate the root mean squared error and mean absolute error from the predictions dataframe\n",
    "lr_metrics_df = predictions_df.\\\n",
    "agg(fn.sqrt(fn.sum(fn.col('abs')*fn.col('abs'))/fn.count('abs')).alias('rmse'),\n",
    "    (fn.sum(fn.col('abs'))/fn.count('abs')).alias('mae'))\n",
    "\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a9967717e559b923a29f78e1f2f8d6b",
     "grade": true,
     "grade_id": "cell-a1ce5f770004bf22",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_array_less(lr_metrics_df.first().rmse, 10)\n",
    "np.testing.assert_array_less(lr_metrics_df.first().mae, 10)\n",
    "np.testing.assert_equal(lr_metrics_df.count(), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
