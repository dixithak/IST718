{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da89413c16b9232417a288f5f4a90d5",
     "grade": false,
     "grade_id": "cell-b11b633c1b5945fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe2047354b19195bdf5522cbf281619",
     "grade": false,
     "grade_id": "cell-018f7df76fbe7856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2044a50756dcbf5ea6c35bf7d42f1",
     "grade": false,
     "grade_id": "cell-baf717df615c90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Admission analysis\n",
    "\n",
    "In this assignment, you will have to do an analysis on graduate admission dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10d9c9cd49d50cafb359604a884025d",
     "grade": false,
     "grade_id": "cell-b3d0fec5fd8fa1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Admission data analysis\n",
    "```console\n",
    "1. Title: Graduate Admission Data\n",
    "\n",
    "2. Sources:\n",
    "    Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
    "    \n",
    "3. Number of Instances: 400\n",
    "\n",
    "4. Numer of Attributes: 8 + numeric chance of admit \n",
    "\n",
    "5. Attribute information:\n",
    "    \n",
    "    1. Region: A,B,C,D,E\n",
    "    2. GRE_Score: out of 340\n",
    "    3. TOEFL_Scores: out of 120 \n",
    "    4. University_Rating: out of 5 \n",
    "    5. SOP (Statement of Purpose): out of 5\n",
    "    6. LOR (Letter of Recommendation): out of 5 \n",
    "    7. CGPA (Undergraduate GPA): out of 10 \n",
    "    8. Research (Research Experience): either 0 or 1 \n",
    "    9. Chance_of_Admit: ranging from 0 to 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba156df7460502db19587cedd3920ffd",
     "grade": false,
     "grade_id": "cell-fbd13f1a46d7ab58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "admission_df = spark.createDataFrame(pd.read_csv('Admission_Predict.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101064f7058d337cfc70fd28780d64e",
     "grade": false,
     "grade_id": "cell-7a1ec8f49ea0c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe.\n",
    "\n",
    "Create a dataframe `admission_sample_df` with the first 30 rows of `admission_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89e882063996b7dab8a5242e3929d2b",
     "grade": false,
     "grade_id": "cell-e80e04372b503a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_sample_df'\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247f4c0aaa64fbba85f4f2e661b003d9",
     "grade": true,
     "grade_id": "cell-57638388c2ad5eb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1 pts - right number of rows\n",
    "np.testing.assert_equal(admission_sample_df.count(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559cf4b7166497727bcb57c9b32e8bd",
     "grade": false,
     "grade_id": "cell-21369ae318d400ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(7 pts)** Below, transform `admission_sample_df` into a Pandas dataframe and do a scatter plot of `GRE_Score` vs `TOEFL_Score`. In addition, grouping each point with different color based on `Chance_of_Admit`. If the chance over 0.6, colored the points blue; otherwise, colored the points red. Last, describe what you find? (Remember to add **axis titles**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeacc9bfe1d258f16eaa1f74412e08f3",
     "grade": true,
     "grade_id": "cell-733193a16ed546b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts: Scatter plot of GRE_Score vs TOEFL_Score\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cebbce497e4fb9cd495a8efd39a760d",
     "grade": true,
     "grade_id": "cell-dd7a31bc0ef827f8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts: What you find based on the scatter plot?\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebd53bbced4b999f064706dad37dbdf",
     "grade": false,
     "grade_id": "cell-ec142e2e68de9605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Perform correlations between SOP, LOR, and CGPA\n",
    "\n",
    "Create a `admission_corr_df` dataframe that contains the correlations between `SOP` and `LOR` as a column `corr_SOP_LOR`, between `LOR` and `CGPA` as `corr_LOR_CGPA`, and `SOP` and `CGPA` as `corr_SOP_CGPA`. (Using admission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56146a17e5c327622b6f1e1760d965",
     "grade": false,
     "grade_id": "cell-df532240f4d92753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_corr_df' here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6f6eea28b7090b37cbb3c9c66b9f3f1",
     "grade": true,
     "grade_id": "cell-cc77c0b74fa5348e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(set(admission_corr_df.columns), \n",
    "                        {'corr_SOP_LOR', 'corr_LOR_CGPA', 'corr_SOP_CGPA'})\n",
    "np.testing.assert_almost_equal(list(admission_corr_df.first().asDict().values()),\n",
    "                               [0.7295925366175836, 0.6702112958281646, 0.718143958057528], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29c5107e1156893d1906558b8878af8",
     "grade": false,
     "grade_id": "cell-6a8aaa697c9bbf35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute mean and standard deviation Change_of_Admit for regions\n",
    "\n",
    "Create `region_chance_df` with the column `region`, `avg_chance`, and `sd_chance`, where `avg_chance` is the average chance of admit in different regions and `sd_chance` is the standard deviation of chance of admit. Sort the resulting dataframe from highest to lowest average chance of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf6636af715d9bd16c4ac9b7e5f6b3c",
     "grade": false,
     "grade_id": "cell-adc9962ca3f172dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c6eedfeb2f9a67085849ddc44eada2",
     "grade": true,
     "grade_id": "cell-3e3efa19ef277303",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('avg_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.7283529411764705],\n",
    " [0.712],\n",
    " [0.7020000000000001],\n",
    " [0.734],\n",
    " [0.7501538461538463]], decimal=3)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('sd_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.1474533587179311],\n",
    " [0.13247461571759256],\n",
    " [0.14784014630931444],\n",
    " [0.14602022038712573],\n",
    " [0.1364103678667368]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33d5db8971f43434dd99419e3704dea3",
     "grade": false,
     "grade_id": "cell-f1bd9070a4f4a096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce1b2c674f73f01533a2d819960d904b",
     "grade": false,
     "grade_id": "cell-398550c98eadbc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dummy variables for region\n",
    "Create a dataframe `dummy_df` with columns `region` as dummy variables, and columns `GRE_Score`, `TOEFL_Score`, `CGPA`, `University_Rating`, and `Chance_of_Admit`. Use region B as the baselines and name the dummy variables `region_A` for region `A` and so on. The dataframe `dummy_df` should not contain the column `region` but only its dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769b5022f018ff379dbc2f57c32cd0e7",
     "grade": false,
     "grade_id": "cell-db7e48e683df42e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create dummy_df below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e681251ccb2ff430f5575dedc3b271",
     "grade": true,
     "grade_id": "cell-f39fae1fa71a3471",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 9)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_A')).first()['sum(Region_A)'], 85)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_D')).first()['sum(Region_D)'], 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b51a725e97536342f8267337dc1cf1",
     "grade": false,
     "grade_id": "cell-8cce282528966eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09f7584104f099b4df6ffa35060ccfe6",
     "grade": false,
     "grade_id": "cell-b08585ead9b207b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8d66ab79dcdf24c5f81fee9f4b36e39",
     "grade": false,
     "grade_id": "cell-d0b5fb8d8706846a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `admission_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3062054c474545b66a732399049ed7a6",
     "grade": false,
     "grade_id": "cell-dcd785c97986afcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 1: Fit model with only `GRE_Score`\n",
    "\n",
    "Create a pipeline that takes **GRE_Score** as a feature to predict **Chance_of_Admit** and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df`. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a5462f85e2da429c5aa44985fd390d",
     "grade": false,
     "grade_id": "cell-c57d53ae996b4bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create 'pipe_model1' below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e25e1c67814e76189a4a6ae37ee6bf0",
     "grade": true,
     "grade_id": "cell-a4893e248e800735",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7db4ca6b9b8ef5cffd712581320f6325",
     "grade": false,
     "grade_id": "cell-0a32f35acf305854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 2: Fit model with `GRE_Score` and `TOEFL_Score`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c188642a605c3326448242ce9f8a2597",
     "grade": false,
     "grade_id": "cell-1d6b9d8550b155a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782baea21ff61b85fa180ef34a127f9c",
     "grade": true,
     "grade_id": "cell-8101d487ebf43e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235be53a2ceb6affa1113f0edbcc156f",
     "grade": false,
     "grade_id": "cell-3a4584e870d7917f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 3: Fit model with region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea814c7a5da239f558a32fb8e3391d",
     "grade": false,
     "grade_id": "cell-d76114eb3ef2a204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model2` below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd910c7fecdadc8ed7d3625be48d8e7",
     "grade": true,
     "grade_id": "cell-3fec64f09c5f9b1a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03cb166d70623c95bd8e3926dcc93069",
     "grade": false,
     "grade_id": "cell-8ae6c91ed48801ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cfcdda4fbb7ff90ad0f41752c2c8d2",
     "grade": false,
     "grade_id": "cell-1c77f9181d77846f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c43910e53176dc89129126996e1c29",
     "grade": false,
     "grade_id": "cell-4868fed0a63693a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8667bcddbc78ac0063269e8ec38f7bda",
     "grade": true,
     "grade_id": "cell-3b822c91b066bf09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb1e1944cf0ec1381c9e168bcb007fe",
     "grade": false,
     "grade_id": "cell-2554e0a148260c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa884e51878e5a17c9e2290add9457d9",
     "grade": false,
     "grade_id": "cell-c90e54ce6ce997f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02183f5be1cfa4d961324c345ebde91b",
     "grade": true,
     "grade_id": "cell-35afdf9356e2d8c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65425c746f594ab1e9ce0f8505a7d704",
     "grade": false,
     "grade_id": "cell-a99d0caf3a210263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1abdc50e622c6c1356c761b7d616188",
     "grade": false,
     "grade_id": "cell-1ecb77ce154ee874",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse_best_df\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97b09637da7cc6b5f5feccc6984c5b9a",
     "grade": true,
     "grade_id": "cell-4d8dbfbdf95c6bc6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356a7b0eec1cf5398a4aafcb9b5d09d",
     "grade": false,
     "grade_id": "cell-737b6d13dffc6cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cf756b46ea0129cd0e630946aa2fb1a",
     "grade": true,
     "grade_id": "cell-3f5687cd81273841",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model\n",
    "\n",
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c481548582d0228e36909c72d902ab6",
     "grade": false,
     "grade_id": "cell-e208c1a9d8454894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41b48cd0aa92ed02d559a50978e9b7",
     "grade": true,
     "grade_id": "cell-2daf591ae711f6d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16063f699d921a471e74c981316bafdf",
     "grade": false,
     "grade_id": "cell-d6e2ab884588f873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking region B as the baseline, what are the top 2 most important features for *increasing chance of admit* and the top 2 most important features for *decreasing chance of admit*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526ee418f78e447d0041045b43ccdfb0",
     "grade": true,
     "grade_id": "cell-1ace5536c0322bdb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
