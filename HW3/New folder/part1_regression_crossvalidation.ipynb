{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da89413c16b9232417a288f5f4a90d5",
     "grade": false,
     "grade_id": "cell-b11b633c1b5945fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe2047354b19195bdf5522cbf281619",
     "grade": false,
     "grade_id": "cell-018f7df76fbe7856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2044a50756dcbf5ea6c35bf7d42f1",
     "grade": false,
     "grade_id": "cell-baf717df615c90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Admission analysis\n",
    "\n",
    "In this assignment, you will have to do an analysis on graduate admission dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10d9c9cd49d50cafb359604a884025d",
     "grade": false,
     "grade_id": "cell-b3d0fec5fd8fa1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Admission data analysis\n",
    "```console\n",
    "1. Title: Graduate Admission Data\n",
    "\n",
    "2. Sources:\n",
    "    Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
    "    \n",
    "3. Number of Instances: 400\n",
    "\n",
    "4. Numer of Attributes: 8 + numeric chance of admit \n",
    "\n",
    "5. Attribute information:\n",
    "    \n",
    "    1. Region: A,B,C,D,E\n",
    "    2. GRE_Score: out of 340\n",
    "    3. TOEFL_Scores: out of 120 \n",
    "    4. University_Rating: out of 5 \n",
    "    5. SOP (Statement of Purpose): out of 5\n",
    "    6. LOR (Letter of Recommendation): out of 5 \n",
    "    7. CGPA (Undergraduate GPA): out of 10 \n",
    "    8. Research (Research Experience): either 0 or 1 \n",
    "    9. Chance_of_Admit: ranging from 0 to 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba156df7460502db19587cedd3920ffd",
     "grade": false,
     "grade_id": "cell-fbd13f1a46d7ab58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "admission_df = spark.createDataFrame(pd.read_csv('Admission_Predict.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101064f7058d337cfc70fd28780d64e",
     "grade": false,
     "grade_id": "cell-7a1ec8f49ea0c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe.\n",
    "\n",
    "Create a dataframe `admission_sample_df` with the first 30 rows of `admission_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89e882063996b7dab8a5242e3929d2b",
     "grade": false,
     "grade_id": "cell-e80e04372b503a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_sample_df'\n",
    "# YOUR CODE HERE\n",
    "admission_sample_df = admission_df.limit(30)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247f4c0aaa64fbba85f4f2e661b003d9",
     "grade": true,
     "grade_id": "cell-57638388c2ad5eb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1 pts - right number of rows\n",
    "np.testing.assert_equal(admission_sample_df.count(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559cf4b7166497727bcb57c9b32e8bd",
     "grade": false,
     "grade_id": "cell-21369ae318d400ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(7 pts)** Below, transform `admission_sample_df` into a Pandas dataframe and do a scatter plot of `GRE_Score` vs `TOEFL_Score`. In addition, grouping each point with different color based on `Chance_of_Admit`. If the chance over 0.6, colored the points blue; otherwise, colored the points red. Last, describe what you find? (Remember to add **axis titles**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeacc9bfe1d258f16eaa1f74412e08f3",
     "grade": true,
     "grade_id": "cell-733193a16ed546b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd2c1d2a730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 pts: Scatter plot of GRE_Score vs TOEFL_Score\n",
    "# YOUR CODE HERE\n",
    "pandas_df_admission = admission_sample_df.toPandas()\n",
    "ax = plt.subplot()\n",
    "pandas_df_admission.query(\"Chance_of_Admit > 0.6\").plot(kind ='scatter',x=\"GRE_Score\",y=\"TOEFL_Score\",color=\"b\",ax=ax,label= \"Chance > 0.6\")\n",
    "pandas_df_admission.query(\"Chance_of_Admit <= 0.6\").plot(kind='scatter',x=\"GRE_Score\",y=\"TOEFL_Score\",color=\"r\",ax=ax,label=\"Chance <= 0.6\")\n",
    "plt.legend()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cebbce497e4fb9cd495a8efd39a760d",
     "grade": true,
     "grade_id": "cell-dd7a31bc0ef827f8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts: What you find based on the scatter plot?\n",
    "# YOUR CODE HERE\n",
    "# For GRE score less than approximately 325 and TOEFL score less than approximately 108, the chances of getting an admit is less than 0.6\n",
    "# But also, the chance of getting an admit is > 0.6 even if the scores are GRE and TOEFL scores are less, this could be because of other factors effecting the chance of admit\n",
    "# As GRE scores are increasing, TOEFL are also increasing. GRE and Toefl are correlated\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebd53bbced4b999f064706dad37dbdf",
     "grade": false,
     "grade_id": "cell-ec142e2e68de9605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Perform correlations between SOP, LOR, and CGPA\n",
    "\n",
    "Create a `admission_corr_df` dataframe that contains the correlations between `SOP` and `LOR` as a column `corr_SOP_LOR`, between `LOR` and `CGPA` as `corr_LOR_CGPA`, and `SOP` and `CGPA` as `corr_SOP_CGPA`. (Using admission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56146a17e5c327622b6f1e1760d965",
     "grade": false,
     "grade_id": "cell-df532240f4d92753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_corr_df' here\n",
    "# YOUR CODE HERE\n",
    "df = sc.parallelize([(admission_df.corr('SOP','LOR'),admission_df.corr('CGPA','LOR'),admission_df.corr('SOP','CGPA'))])\n",
    "admission_corr_df = df.toDF([\"corr_SOP_LOR\",\"corr_LOR_CGPA\",\"corr_SOP_CGPA\"])\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6f6eea28b7090b37cbb3c9c66b9f3f1",
     "grade": true,
     "grade_id": "cell-cc77c0b74fa5348e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(set(admission_corr_df.columns), \n",
    "                        {'corr_SOP_LOR', 'corr_LOR_CGPA', 'corr_SOP_CGPA'})\n",
    "np.testing.assert_almost_equal(list(admission_corr_df.first().asDict().values()),\n",
    "                               [0.7295925366175836, 0.6702112958281646, 0.718143958057528], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29c5107e1156893d1906558b8878af8",
     "grade": false,
     "grade_id": "cell-6a8aaa697c9bbf35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute mean and standard deviation Change_of_Admit for regions\n",
    "\n",
    "Create `region_chance_df` with the column `region`, `avg_chance`, and `sd_chance`, where `avg_chance` is the average chance of admit in different regions and `sd_chance` is the standard deviation of chance of admit. Sort the resulting dataframe from highest to lowest average chance of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf6636af715d9bd16c4ac9b7e5f6b3c",
     "grade": false,
     "grade_id": "cell-adc9962ca3f172dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "region_chance_df = admission_df.groupBy('region').\\\n",
    "agg(fn.mean('Chance_of_Admit').alias(\"avg_chance\"),fn.stddev_samp('Chance_of_admit').alias(\"sd_chance\")).\\\n",
    "    sort('avg_chance',ascending=False) \n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c6eedfeb2f9a67085849ddc44eada2",
     "grade": true,
     "grade_id": "cell-3e3efa19ef277303",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('avg_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.7283529411764705],\n",
    " [0.712],\n",
    " [0.7020000000000001],\n",
    " [0.734],\n",
    " [0.7501538461538463]], decimal=3)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('sd_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.1474533587179311],\n",
    " [0.13247461571759256],\n",
    " [0.14784014630931444],\n",
    " [0.14602022038712573],\n",
    " [0.1364103678667368]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33d5db8971f43434dd99419e3704dea3",
     "grade": false,
     "grade_id": "cell-f1bd9070a4f4a096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce1b2c674f73f01533a2d819960d904b",
     "grade": false,
     "grade_id": "cell-398550c98eadbc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dummy variables for region\n",
    "Create a dataframe `dummy_df` with columns `region` as dummy variables, and columns `GRE_Score`, `TOEFL_Score`, `CGPA`, `University_Rating`, and `Chance_of_Admit`. Use region B as the baselines and name the dummy variables `region_A` for region `A` and so on. The dataframe `dummy_df` should not contain the column `region` but only its dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769b5022f018ff379dbc2f57c32cd0e7",
     "grade": false,
     "grade_id": "cell-db7e48e683df42e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create dummy_df below\n",
    "# YOUR CODE HERE\n",
    "df2 = admission_df.withColumn('Region_A',(fn.col('region')==\"A\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_B',(fn.col('region')==\"B\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_C',(fn.col('region')==\"C\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_D',(fn.col('region')==\"D\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_E',(fn.col('region')==\"E\").cast(\"int\"))\n",
    "dummy_df = df2.select(\"region_A\",\"region_C\",\"region_D\",\"region_E\",\"GRE_Score\",\"TOEFL_Score\",\"CGPA\",\"University_Rating\",\"Chance_of_Admit\")\n",
    "#dummy_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e681251ccb2ff430f5575dedc3b271",
     "grade": true,
     "grade_id": "cell-f39fae1fa71a3471",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 9)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_A')).first()['sum(Region_A)'], 85)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_D')).first()['sum(Region_D)'], 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b51a725e97536342f8267337dc1cf1",
     "grade": false,
     "grade_id": "cell-8cce282528966eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09f7584104f099b4df6ffa35060ccfe6",
     "grade": false,
     "grade_id": "cell-b08585ead9b207b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# points in training:  227\n",
      "# points in validation:  126\n",
      "# points in testing:  47\n"
     ]
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8d66ab79dcdf24c5f81fee9f4b36e39",
     "grade": false,
     "grade_id": "cell-d0b5fb8d8706846a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `admission_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3062054c474545b66a732399049ed7a6",
     "grade": false,
     "grade_id": "cell-dcd785c97986afcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 1: Fit model with only `GRE_Score`\n",
    "\n",
    "Create a pipeline that takes **GRE_Score** as a feature to predict **Chance_of_Admit** and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df`. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a5462f85e2da429c5aa44985fd390d",
     "grade": false,
     "grade_id": "cell-c57d53ae996b4bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create 'pipe_model1' below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model1 = Pipeline(stages =[feature.VectorAssembler(inputCols =['GRE_Score'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e25e1c67814e76189a4a6ae37ee6bf0",
     "grade": true,
     "grade_id": "cell-a4893e248e800735",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7db4ca6b9b8ef5cffd712581320f6325",
     "grade": false,
     "grade_id": "cell-0a32f35acf305854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 2: Fit model with `GRE_Score` and `TOEFL_Score`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c188642a605c3326448242ce9f8a2597",
     "grade": false,
     "grade_id": "cell-1d6b9d8550b155a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model2 = Pipeline(stages =[feature.VectorAssembler(inputCols =['GRE_Score','TOEFL_Score'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782baea21ff61b85fa180ef34a127f9c",
     "grade": true,
     "grade_id": "cell-8101d487ebf43e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235be53a2ceb6affa1113f0edbcc156f",
     "grade": false,
     "grade_id": "cell-3a4584e870d7917f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 3: Fit model with region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea814c7a5da239f558a32fb8e3391d",
     "grade": false,
     "grade_id": "cell-d76114eb3ef2a204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model2` below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "pipe_model3 = Pipeline(stages =[feature.VectorAssembler(inputCols =['region_A','region_C','region_D','region_E','GRE_Score','TOEFL_Score','CGPA','University_Rating'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd910c7fecdadc8ed7d3625be48d8e7",
     "grade": true,
     "grade_id": "cell-3fec64f09c5f9b1a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03cb166d70623c95bd8e3926dcc93069",
     "grade": false,
     "grade_id": "cell-8ae6c91ed48801ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cfcdda4fbb7ff90ad0f41752c2c8d2",
     "grade": false,
     "grade_id": "cell-1c77f9181d77846f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c43910e53176dc89129126996e1c29",
     "grade": false,
     "grade_id": "cell-4868fed0a63693a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "p1 = pipe_model1.transform(validation_df)\n",
    "rmse1 = p1.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse1_df = spark.createDataFrame(rmse1)\n",
    "\n",
    "p2 = pipe_model2.transform(validation_df)\n",
    "rmse2 = p2.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse2_df = spark.createDataFrame(rmse2)\n",
    "\n",
    "p3 = pipe_model3.transform(validation_df)\n",
    "rmse3 = p3.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse3_df = spark.createDataFrame(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.08283242435572377|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.07570520768216206|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.06825953330162493|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8667bcddbc78ac0063269e8ec38f7bda",
     "grade": true,
     "grade_id": "cell-3b822c91b066bf09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb1e1944cf0ec1381c9e168bcb007fe",
     "grade": false,
     "grade_id": "cell-2554e0a148260c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa884e51878e5a17c9e2290add9457d9",
     "grade": false,
     "grade_id": "cell-c90e54ce6ce997f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "best_model = pipe_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02183f5be1cfa4d961324c345ebde91b",
     "grade": true,
     "grade_id": "cell-35afdf9356e2d8c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65425c746f594ab1e9ce0f8505a7d704",
     "grade": false,
     "grade_id": "cell-a99d0caf3a210263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1abdc50e622c6c1356c761b7d616188",
     "grade": false,
     "grade_id": "cell-1ecb77ce154ee874",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse_best_df\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "p_best = best_model.transform(testing_df)\n",
    "rmse_best_df = p_best.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse_best_df = spark.createDataFrame(rmse_best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97b09637da7cc6b5f5feccc6984c5b9a",
     "grade": true,
     "grade_id": "cell-4d8dbfbdf95c6bc6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356a7b0eec1cf5398a4aafcb9b5d09d",
     "grade": false,
     "grade_id": "cell-737b6d13dffc6cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cf756b46ea0129cd0e630946aa2fb1a",
     "grade": true,
     "grade_id": "cell-3f5687cd81273841",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                rmse|\n",
      "+--------------------+\n",
      "|0.056024696786660146|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1 pts)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "#The best estimated generalization performance of the best model is root mean squared error.\n",
    "rmse_best_df.show()\n",
    "#it is 0.0056 for the best model we considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model\n",
    "\n",
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c481548582d0228e36909c72d902ab6",
     "grade": false,
     "grade_id": "cell-e208c1a9d8454894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model_best = Pipeline(stages =[feature.VectorAssembler(inputCols =[\"region_A\",\"region_C\",\"region_D\",\"region_E\",\"GRE_Score\",\"TOEFL_Score\",\"CGPA\",\"University_Rating\"],\n",
    "                                               outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41b48cd0aa92ed02d559a50978e9b7",
     "grade": true,
     "grade_id": "cell-2daf591ae711f6d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16063f699d921a471e74c981316bafdf",
     "grade": false,
     "grade_id": "cell-d6e2ab884588f873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking region B as the baseline, what are the top 2 most important features for *increasing chance of admit* and the top 2 most important features for *decreasing chance of admit*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526ee418f78e447d0041045b43ccdfb0",
     "grade": true,
     "grade_id": "cell-1ace5536c0322bdb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0059, 0.0121, 0.0205, 0.0005, 0.0021, 0.0027, 0.1366, 0.0116])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# The top 2 most important features for increasing chance of admit are CGPA(coefficient = 0.1366) and belonging to region D(coefficient=0.0205)\n",
    "# The top 2 most important features for decreasing the chance of admit are region E(Coefficient= 0.0005) and GRE_Score(coefficient=0.0021)\n",
    "pipe_model_best.stages[1].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
