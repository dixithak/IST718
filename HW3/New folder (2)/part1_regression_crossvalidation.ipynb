{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da89413c16b9232417a288f5f4a90d5",
     "grade": false,
     "grade_id": "cell-b11b633c1b5945fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe2047354b19195bdf5522cbf281619",
     "grade": false,
     "grade_id": "cell-018f7df76fbe7856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2044a50756dcbf5ea6c35bf7d42f1",
     "grade": false,
     "grade_id": "cell-baf717df615c90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Admission analysis\n",
    "\n",
    "In this assignment, you will have to do an analysis on graduate admission dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10d9c9cd49d50cafb359604a884025d",
     "grade": false,
     "grade_id": "cell-b3d0fec5fd8fa1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Admission data analysis\n",
    "```console\n",
    "1. Title: Graduate Admission Data\n",
    "\n",
    "2. Sources:\n",
    "    Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
    "    \n",
    "3. Number of Instances: 400\n",
    "\n",
    "4. Numer of Attributes: 8 + numeric chance of admit \n",
    "\n",
    "5. Attribute information:\n",
    "    \n",
    "    1. Region: A,B,C,D,E\n",
    "    2. GRE_Score: out of 340\n",
    "    3. TOEFL_Scores: out of 120 \n",
    "    4. University_Rating: out of 5 \n",
    "    5. SOP (Statement of Purpose): out of 5\n",
    "    6. LOR (Letter of Recommendation): out of 5 \n",
    "    7. CGPA (Undergraduate GPA): out of 10 \n",
    "    8. Research (Research Experience): either 0 or 1 \n",
    "    9. Chance_of_Admit: ranging from 0 to 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba156df7460502db19587cedd3920ffd",
     "grade": false,
     "grade_id": "cell-fbd13f1a46d7ab58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "admission_df = spark.createDataFrame(pd.read_csv('Admission_Predict.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101064f7058d337cfc70fd28780d64e",
     "grade": false,
     "grade_id": "cell-7a1ec8f49ea0c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe.\n",
    "\n",
    "Create a dataframe `admission_sample_df` with the first 30 rows of `admission_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89e882063996b7dab8a5242e3929d2b",
     "grade": false,
     "grade_id": "cell-e80e04372b503a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_sample_df'\n",
    "# YOUR CODE HERE\n",
    "admission_sample_df = admission_df.limit(30)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247f4c0aaa64fbba85f4f2e661b003d9",
     "grade": true,
     "grade_id": "cell-57638388c2ad5eb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1 pts - right number of rows\n",
    "np.testing.assert_equal(admission_sample_df.count(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559cf4b7166497727bcb57c9b32e8bd",
     "grade": false,
     "grade_id": "cell-21369ae318d400ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(7 pts)** Below, transform `admission_sample_df` into a Pandas dataframe and do a scatter plot of `GRE_Score` vs `TOEFL_Score`. In addition, grouping each point with different color based on `Chance_of_Admit`. If the chance over 0.6, colored the points blue; otherwise, colored the points red. Last, describe what you find? (Remember to add **axis titles**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeacc9bfe1d258f16eaa1f74412e08f3",
     "grade": true,
     "grade_id": "cell-733193a16ed546b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5239681be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 pts: Scatter plot of GRE_Score vs TOEFL_Score\n",
    "# YOUR CODE HERE\n",
    "pandas_df_admission = admission_sample_df.toPandas()\n",
    "ax = plt.subplot()\n",
    "pandas_df_admission.query(\"Chance_of_Admit > 0.6\").plot(kind ='scatter',x=\"GRE_Score\",y=\"TOEFL_Score\",color=\"b\",ax=ax,label= \"Chance > 0.6\")\n",
    "pandas_df_admission.query(\"Chance_of_Admit <= 0.6\").plot(kind='scatter',x=\"GRE_Score\",y=\"TOEFL_Score\",color=\"r\",ax=ax,label=\"Chance <= 0.6\")\n",
    "plt.legend()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cebbce497e4fb9cd495a8efd39a760d",
     "grade": true,
     "grade_id": "cell-dd7a31bc0ef827f8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts: What you find based on the scatter plot?\n",
    "# YOUR CODE HERE\n",
    "# For GRE score less than approximately 325 and TOEFL score less than approximately 108, the chances of getting an admit is less than 0.6\n",
    "# But also, the chance of getting an admit is > 0.6 even if the scores are GRE and TOEFL scores are less, this could be because of other factors effecting the chance of admit\n",
    "# As GRE scores are increasing, TOEFL are also increasing. GRE and Toefl are correlated\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebd53bbced4b999f064706dad37dbdf",
     "grade": false,
     "grade_id": "cell-ec142e2e68de9605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Perform correlations between SOP, LOR, and CGPA\n",
    "\n",
    "Create a `admission_corr_df` dataframe that contains the correlations between `SOP` and `LOR` as a column `corr_SOP_LOR`, between `LOR` and `CGPA` as `corr_LOR_CGPA`, and `SOP` and `CGPA` as `corr_SOP_CGPA`. (Using admission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56146a17e5c327622b6f1e1760d965",
     "grade": false,
     "grade_id": "cell-df532240f4d92753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_corr_df' here\n",
    "# YOUR CODE HERE\n",
    "df = sc.parallelize([(admission_df.corr('SOP','LOR'),admission_df.corr('CGPA','LOR'),admission_df.corr('SOP','CGPA'))])\n",
    "admission_corr_df = df.toDF([\"corr_SOP_LOR\",\"corr_LOR_CGPA\",\"corr_SOP_CGPA\"])\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6f6eea28b7090b37cbb3c9c66b9f3f1",
     "grade": true,
     "grade_id": "cell-cc77c0b74fa5348e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(set(admission_corr_df.columns), \n",
    "                        {'corr_SOP_LOR', 'corr_LOR_CGPA', 'corr_SOP_CGPA'})\n",
    "np.testing.assert_almost_equal(list(admission_corr_df.first().asDict().values()),\n",
    "                               [0.7295925366175836, 0.6702112958281646, 0.718143958057528], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29c5107e1156893d1906558b8878af8",
     "grade": false,
     "grade_id": "cell-6a8aaa697c9bbf35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute mean and standard deviation Change_of_Admit for regions\n",
    "\n",
    "Create `region_chance_df` with the column `region`, `avg_chance`, and `sd_chance`, where `avg_chance` is the average chance of admit in different regions and `sd_chance` is the standard deviation of chance of admit. Sort the resulting dataframe from highest to lowest average chance of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf6636af715d9bd16c4ac9b7e5f6b3c",
     "grade": false,
     "grade_id": "cell-adc9962ca3f172dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "region_chance_df = admission_df.groupBy('region').\\\n",
    "agg(fn.mean('Chance_of_Admit').alias(\"avg_chance\"),fn.stddev_samp('Chance_of_admit').alias(\"sd_chance\")).\\\n",
    "    sort('avg_chance',ascending=False) \n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c6eedfeb2f9a67085849ddc44eada2",
     "grade": true,
     "grade_id": "cell-3e3efa19ef277303",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('avg_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.7283529411764705],\n",
    " [0.712],\n",
    " [0.7020000000000001],\n",
    " [0.734],\n",
    " [0.7501538461538463]], decimal=3)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('sd_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.1474533587179311],\n",
    " [0.13247461571759256],\n",
    " [0.14784014630931444],\n",
    " [0.14602022038712573],\n",
    " [0.1364103678667368]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33d5db8971f43434dd99419e3704dea3",
     "grade": false,
     "grade_id": "cell-f1bd9070a4f4a096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce1b2c674f73f01533a2d819960d904b",
     "grade": false,
     "grade_id": "cell-398550c98eadbc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dummy variables for region\n",
    "Create a dataframe `dummy_df` with columns `region` as dummy variables, and columns `GRE_Score`, `TOEFL_Score`, `CGPA`, `University_Rating`, and `Chance_of_Admit`. Use region B as the baselines and name the dummy variables `region_A` for region `A` and so on. The dataframe `dummy_df` should not contain the column `region` but only its dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769b5022f018ff379dbc2f57c32cd0e7",
     "grade": false,
     "grade_id": "cell-db7e48e683df42e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create dummy_df below\n",
    "# YOUR CODE HERE\n",
    "df2 = admission_df.withColumn('Region_A',(fn.col('region')==\"A\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_B',(fn.col('region')==\"B\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_C',(fn.col('region')==\"C\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_D',(fn.col('region')==\"D\").cast(\"int\"))\n",
    "df2 = df2.withColumn('region_E',(fn.col('region')==\"E\").cast(\"int\"))\n",
    "dummy_df = df2.select(\"region_A\",\"region_C\",\"region_D\",\"region_E\",\"GRE_Score\",\"TOEFL_Score\",\"CGPA\",\"University_Rating\",\"Chance_of_Admit\")\n",
    "#dummy_df.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e681251ccb2ff430f5575dedc3b271",
     "grade": true,
     "grade_id": "cell-f39fae1fa71a3471",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 9)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_A')).first()['sum(Region_A)'], 85)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_D')).first()['sum(Region_D)'], 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b51a725e97536342f8267337dc1cf1",
     "grade": false,
     "grade_id": "cell-8cce282528966eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09f7584104f099b4df6ffa35060ccfe6",
     "grade": false,
     "grade_id": "cell-b08585ead9b207b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# points in training:  227\n",
      "# points in validation:  126\n",
      "# points in testing:  47\n"
     ]
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8d66ab79dcdf24c5f81fee9f4b36e39",
     "grade": false,
     "grade_id": "cell-d0b5fb8d8706846a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `admission_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3062054c474545b66a732399049ed7a6",
     "grade": false,
     "grade_id": "cell-dcd785c97986afcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 1: Fit model with only `GRE_Score`\n",
    "\n",
    "Create a pipeline that takes **GRE_Score** as a feature to predict **Chance_of_Admit** and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df`. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a5462f85e2da429c5aa44985fd390d",
     "grade": false,
     "grade_id": "cell-c57d53ae996b4bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create 'pipe_model1' below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model1 = Pipeline(stages =[feature.VectorAssembler(inputCols =['GRE_Score'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e25e1c67814e76189a4a6ae37ee6bf0",
     "grade": true,
     "grade_id": "cell-a4893e248e800735",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7db4ca6b9b8ef5cffd712581320f6325",
     "grade": false,
     "grade_id": "cell-0a32f35acf305854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 2: Fit model with `GRE_Score` and `TOEFL_Score`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c188642a605c3326448242ce9f8a2597",
     "grade": false,
     "grade_id": "cell-1d6b9d8550b155a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model2 = Pipeline(stages =[feature.VectorAssembler(inputCols =['GRE_Score','TOEFL_Score'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782baea21ff61b85fa180ef34a127f9c",
     "grade": true,
     "grade_id": "cell-8101d487ebf43e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235be53a2ceb6affa1113f0edbcc156f",
     "grade": false,
     "grade_id": "cell-3a4584e870d7917f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 3: Fit model with region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea814c7a5da239f558a32fb8e3391d",
     "grade": false,
     "grade_id": "cell-d76114eb3ef2a204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model2` below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "pipe_model3 = Pipeline(stages =[feature.VectorAssembler(inputCols =['region_A','region_C','region_D','region_E','GRE_Score','TOEFL_Score','CGPA','University_Rating'],outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd910c7fecdadc8ed7d3625be48d8e7",
     "grade": true,
     "grade_id": "cell-3fec64f09c5f9b1a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03cb166d70623c95bd8e3926dcc93069",
     "grade": false,
     "grade_id": "cell-8ae6c91ed48801ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cfcdda4fbb7ff90ad0f41752c2c8d2",
     "grade": false,
     "grade_id": "cell-1c77f9181d77846f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c43910e53176dc89129126996e1c29",
     "grade": false,
     "grade_id": "cell-4868fed0a63693a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "p1 = pipe_model1.transform(validation_df)\n",
    "rmse1 = p1.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse1_df = spark.createDataFrame(rmse1)\n",
    "\n",
    "p2 = pipe_model2.transform(validation_df)\n",
    "rmse2 = p2.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse2_df = spark.createDataFrame(rmse2)\n",
    "\n",
    "p3 = pipe_model3.transform(validation_df)\n",
    "rmse3 = p3.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse3_df = spark.createDataFrame(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.08283242435572377|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.07570520768216206|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.06825953330162493|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8667bcddbc78ac0063269e8ec38f7bda",
     "grade": true,
     "grade_id": "cell-3b822c91b066bf09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb1e1944cf0ec1381c9e168bcb007fe",
     "grade": false,
     "grade_id": "cell-2554e0a148260c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa884e51878e5a17c9e2290add9457d9",
     "grade": false,
     "grade_id": "cell-c90e54ce6ce997f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "best_model = pipe_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02183f5be1cfa4d961324c345ebde91b",
     "grade": true,
     "grade_id": "cell-35afdf9356e2d8c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65425c746f594ab1e9ce0f8505a7d704",
     "grade": false,
     "grade_id": "cell-a99d0caf3a210263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1abdc50e622c6c1356c761b7d616188",
     "grade": false,
     "grade_id": "cell-1ecb77ce154ee874",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse_best_df\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "p_best = best_model.transform(testing_df)\n",
    "rmse_best_df = p_best.agg(fn.sqrt(fn.mean((fn.col('Chance_of_Admit')-fn.col('prediction'))**2)).alias('rmse')).collect()\n",
    "rmse_best_df = spark.createDataFrame(rmse_best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97b09637da7cc6b5f5feccc6984c5b9a",
     "grade": true,
     "grade_id": "cell-4d8dbfbdf95c6bc6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356a7b0eec1cf5398a4aafcb9b5d09d",
     "grade": false,
     "grade_id": "cell-737b6d13dffc6cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cf756b46ea0129cd0e630946aa2fb1a",
     "grade": true,
     "grade_id": "cell-3f5687cd81273841",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                rmse|\n",
      "+--------------------+\n",
      "|0.056024696786660146|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1 pts)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "#The best estimated generalization performance of the best model is root mean squared error.\n",
    "rmse_best_df.show()\n",
    "#it is 0.056 for the best model we considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model\n",
    "\n",
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c481548582d0228e36909c72d902ab6",
     "grade": false,
     "grade_id": "cell-e208c1a9d8454894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "pipe_model_best = Pipeline(stages =[feature.VectorAssembler(inputCols =[\"region_A\",\"region_C\",\"region_D\",\"region_E\",\"GRE_Score\",\"TOEFL_Score\",\"CGPA\",\"University_Rating\"],\n",
    "                                               outputCol ='features'),\n",
    "                      regression.LinearRegression(labelCol='Chance_of_Admit',featuresCol='features')]).fit(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41b48cd0aa92ed02d559a50978e9b7",
     "grade": true,
     "grade_id": "cell-2daf591ae711f6d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16063f699d921a471e74c981316bafdf",
     "grade": false,
     "grade_id": "cell-d6e2ab884588f873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking region B as the baseline, what are the top 2 most important features for *increasing chance of admit* and the top 2 most important features for *decreasing chance of admit*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526ee418f78e447d0041045b43ccdfb0",
     "grade": true,
     "grade_id": "cell-1ace5536c0322bdb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0059, 0.0121, 0.0205, 0.0005, 0.0021, 0.0027, 0.1366, 0.0116])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# The top 2 most important features for increasing chance of admit are CGPA(coefficient = 0.1366) and belonging to region D(coefficient=0.0205)\n",
    "# The top 2 most important features for decreasing the chance of admit are region E(Coefficient= 0.0005) and GRE_Score(coefficient=0.0021)\n",
    "pipe_model_best.stages[1].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
